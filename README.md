# SelfSupervised-Speech-models-repo
This is for presentation about self supervised models.<br/>

  1. 
      HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units (Facebook)<br/>
      https://arxiv.org/abs/2106.07447<br/>
      https://huggingface.co/docs/transformers/model_doc/hubert<br/>
      https://ai.facebook.com/blog/hubert-self-supervised-representation-learning-for-speech-recognition-generation-and-compression/<br/>
      https://blog.devgenius.io/hubert-explained-6ec7c2bf71fc<br/>
      https://jonathanbgn.com/2021/10/30/hubert-visually-explained.html (* This is very good)<br/>
      https://github.com/facebookresearch/av_hubert<br/>
      
  2. 
      WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing (Microsoft)<br/>
      https://arxiv.org/abs/2110.13900<br/>
      https://huggingface.co/docs/transformers/model_doc/wavlm<br/>
      https://github.com/microsoft/unilm/tree/master/wavlm<br/>
  
  3. 
      Wav2vec2: A Framework for Self-Supervised Learning of Speech Representations<br/>
      https://arxiv.org/abs/2006.11477<br/>
      https://huggingface.co/masoudmzb/wav2vec2-xlsr-multilingual-53-fa<br/>
      https://github.com/Hamtech-ai/wav2vec2-fa<br/>
      https://jonathanbgn.com/2021/09/30/illustrated-wav2vec-2.html (* This is very good)<br/>
      https://aws.amazon.com/blogs/machine-learning/fine-tune-and-deploy-a-wav2vec2-model-for-speech-recognition-with-hugging-face-and-amazon-sagemaker/<br/>
      https://arxiv.org/abs/2107.13530<br/>
      https://arxiv.org/abs/2104.01027 (ROBUST WAV2VEC 2.0: ANALYZING DOMAIN SHIFT IN SELF-SUPERVISED PRE-TRAINING)<br/>
      https://huggingface.co/blog/fine-tune-xlsr-wav2vec2 (* This is very good)<br/>
      https://huggingface.co/models?arxiv=arxiv:2104.01027<br/>
      https://arxiv.org/abs/2101.06699 (Efficiently Fusing Pretrained Acoustic and Linguistic Encoders for Low-resource Speech Recognition)<br/>
      https://pytorch.org/tutorials/intermediate/speech_recognition_pipeline_tutorial.html<br/>
      
  4.  
      UniSpeechSAT: SELF-SUPERVISED LEARNING FOR SPEECH RECOGNITION WITH INTERMEDIATE LAYER SUPERVISION (Microsoft)<br/>
      https://arxiv.org/abs/2112.08778<br/>
      https://github.com/microsoft/UniSpeech<br/>
      

 5. Compare models:<br/>      
      Superb benchmark : https://superbbenchmark.org/leaderboard?subset=Public+Set<br/>
      
 6. Other:<br/>
      https://arxiv.org/pdf/2110.05777.pdf (Large-scale Self-Supervised Speech Representation Learning for Automatic Speaker Verification)<br/>
      https://arxiv.org/pdf/2206.01685.pdf (Toward a realistic model of speech processing in the brain with self-supervised learning) (* It is Important)<br/>
      https://syncedreview.com/2019/02/22/yann-lecun-cake-analogy-2-0/<br/>
      
 7. Implement Guide:<br/>
      https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec<br/>
      https://huggingface.co/docs/transformers/model_doc/wavlm#transformers.WavLMForXVector<br/>
        https://colab.research.google.com/github/m3hrdadfi/notebooks/blob/main/Fine_Tune_XLSR_Wav2Vec2_on_Persian_ShEMO_ASR_with_%F0%9F%A4%97_Transformers_ipynb.ipynb<br/>
